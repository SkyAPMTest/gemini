#gemini conf
gemini.intervalTime=10

#kafka conf
bootstrap.servers=10.1.241.18:9092,10.1.241.19:9092,10.1.241.20:9092
#bootstrap.servers=localhost:9092
key.deserializer=org.apache.kafka.common.serialization.LongDeserializer
value.deserializer=org.apache.kafka.common.serialization.ByteArrayDeserializer
auto.offset.reset=latest
max.poll.records=20000
max.partition.fetch.bytes=104857600
fetch.max.bytes=5242880000

#zookeeper conf
zk.servers=master:29181,slave1:29181,slave2:29181
#zk.servers=localhost:2181
zk.session.timeout=3000

#Spark conf
spark.master=spark://spark:6066
#spark.master=local
spark.streaming.kafka.consumer.poll.ms=10000
spark.streaming.receiver.writeAheadLog.enable=true
spark.streaming.kafka.consumer.cache.initialCapacity=16
spark.streaming.kafka.consumer.cache.maxCapacity=128
spark.streaming.backpressure.enabled=true
spark.streaming.kafka.maxRatePerPartition=10000
spark.streaming.receiver.maxRate=200000

# MongoDB conf
spark.mongodb.output.uri=mongodb://10.1.241.18:27017/
spark.mongodb.output.database=gemini

#Redis Conf
redis.host=
redis.port=
redis.timeout=
